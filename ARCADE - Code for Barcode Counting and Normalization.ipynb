{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333af22d",
   "metadata": {},
   "source": [
    "# Import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e83159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to navigate and gather files \n",
    "import pathlib \n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for FASTQ file parsing \n",
    "import Bio\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f898120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from statistics import mean\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c14570",
   "metadata": {},
   "source": [
    "# Obtain the list of FASTQ files to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a6d3e",
   "metadata": {},
   "source": [
    "Each next-generation sequencing library encompassed one 96-well plate of samples. Some sequencing libraries were run on multiple lanes. Barcode recovery was not substantially affected by the lane on which a sequencing library was run. The following information explains the file naming conventions used for the SRA entries: \n",
    "\n",
    "Sequencing Run: 6512S - Moderna-vaccinated cohort samples + pre-pandemic & convalescent donor samples\n",
    "- Lane 1: Plate 2 (Samples D23-17602 through D23-17697), Replicate 1 \n",
    "\n",
    "Sequencing Run: 6540S - Moderna-vaccinated cohort samples + pre-pandemic & convalescent donor samples\n",
    "- Lane 2: Plate 2 (Samples D23-17602 through D23-17697), Replicate 2\n",
    "- Lane 3: Plate 1 (Samples D23-17505 through D23-17600), Replicate 1\n",
    "- Lane 4: Plate 1 (Samples D23-17505 through D23-17600), Replicate 2\n",
    "\n",
    "Sequencing Run: 6658S - Moderna-vaccinated cohort samples + pre-pandemic & convalescent donor samples\n",
    "- Lane 1: Plate 3 (Samples D24-4494 through D24-4589), Replicate 1\n",
    "- Lane 2: Plate 3 (Samples D24-4494 through D24-4589), Replicate 2\n",
    "- Lane 3: Plate 4 (Samples D24-4591 through D24-4686), Replicate 1\n",
    "- Lane 4: Plate 4 (Samples D24-4591 through D24-4686), Replicate 1\n",
    "\n",
    "Sequencing Run: 6697S - J&J-vaccinated cohort samples\n",
    "- Lane 1: Plate 5 (Samples D24-6269 through D24-6364)\n",
    "- Lane 2: Plate 6 (Samples D24-6366 through D24-6461)\n",
    "- Lane 3: Plate 7 (Samples D24-6463 through D24-6558)\n",
    "\n",
    "Sequencing Run: 7182S - Neutralization assay samples\n",
    "- All four lanes ran the same set of samples\n",
    "- Only the 48/96 samples from this sequencing library that were from the neutralization assay are available on the SRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe544d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path for the folder containing the sequencing files \n",
    "# relative to the path of the current working directory \n",
    "seq_file_folder = '/folder_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of all the FASTQ files needed (separated by Read 1 and Read 2)\n",
    "\n",
    "# Obtain Read 1 for each sample\n",
    "# fastq_paths_r1 = sorted(Path(seq_file_folder).glob('**/*_1_sequence.fastq'))\n",
    "\n",
    "# Obtain Read 2 for each sample \n",
    "fastq_paths_r2 = sorted(Path(seq_file_folder).glob('**/*_2_sequence.fastq'))\n",
    "\n",
    "\n",
    "# Note: only Read 2 was used in our analyses. In Read 2, the barcode is located \n",
    "#       closer to the start of the read, placing it in a region where sequencing \n",
    "#       accuracy is likely to be higher. \n",
    "\n",
    "# Note: ** means all folders within the current folder. \n",
    "# Note: * means files ending in the text following * will be obtained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of file paths obtained \n",
    "print(f'Number of file paths: {len(fastq_paths_r2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd6b3c",
   "metadata": {},
   "source": [
    "# Load information about the library barcodes and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d38dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of library member barcode assignments into a dataframe \n",
    "bc_df = pd.read_excel('Barcode List.xlsx')\n",
    "\n",
    "# Note: the columns include Library Member Name, Barcode Number, \n",
    "# Barcode Sequence (Forward), Barcode Sequence (Reverse), and Type of Virus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list(s) of samples into a dataframe  \n",
    "samp_df = pd.read_excel('Samples List.xlsx')\n",
    "\n",
    "# Note: the sample names in the provided spreadsheet correspond to the end of each \"Library Name\" \n",
    "#       in the SRA. These sample names/\"Library Name\" ends are shared across the multiple lanes \n",
    "#       running the same plate/sequencing library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb9a3a",
   "metadata": {},
   "source": [
    "# Obtain barcode counts from the reads in the FASTQ files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce16d3",
   "metadata": {},
   "source": [
    "Since some library member barcodes are separated by short Hamming distances, only read sequences that match barcodes exactly are counted in the final barcode counts for each library member.\n",
    "\n",
    "For simplicity, this code assumes that all FASTQ files and reads are formatted correctly. A try-catch exception should be included if files and reads are likely to have errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1300e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that creates empty dataframes to store barcode counts and barcode recovery information \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# lib_bc_list: list of the library member barcode sequences\n",
    "# list_of_samps: list of the samples in the sequencing run \n",
    "\n",
    "def make_bc_dfs(list_of_samps, lib_bc_list): \n",
    "    \n",
    "    # Create a dataframe to store the barcode counts \n",
    "    bc_counts = pd.DataFrame(index = lib_bc_list)\n",
    "    \n",
    "    # Create a dataframe to store information on barcode recovery  \n",
    "    bc_recovery = pd.DataFrame(0, \n",
    "                               index = list_of_samps, \n",
    "                               columns = ['Number of Reads per Sample', \n",
    "                                          'Number of Barcodes Recovered per Sample',\n",
    "                                          'Percent Barcode Recovery'])\n",
    "    \n",
    "    # Create a dataframe to store quality score information on reads \n",
    "    rd_qual_accepted = pd.DataFrame(index = list_of_samps, \n",
    "                                    columns = ['Number of Accepted Reads',\n",
    "                                               'Mean Quality Score'])\n",
    "    rd_qual_discarded = pd.DataFrame(index = list_of_samps, \n",
    "                                     columns = ['Number of Discarded Reads', \n",
    "                                                'Mean Quality Score'])\n",
    "    \n",
    "    return bc_counts, bc_recovery, rd_qual_accepted, rd_qual_discarded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that counts barcodes and updates a dictionary with the resulting counts\n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# lib_bc_list: list of the library member barcode sequences\n",
    "# list_of_samps: list of the samples in the sequencing run \n",
    "# fastq_paths: list of path objects that link to the FASTQ files\n",
    "# qual_score_cutoff: int that designates the average quality score under which a read\n",
    "#                    should be removed from downstream analyses; input -1 to use all reads \n",
    "# counts_df: an empty dataframe generated by the previous cell that will hold the barcode counts \n",
    "# rec_df: an empty dataframe generated by the previous cell that will hold the barcode recovery info\n",
    "# qual_acc_df: an empty dataframe generated by the previous cell that will hold the total number \n",
    "#              and mean quality scores of reads that meet the qual_score_cutoff\n",
    "# qual_dis_df: an empty dataframe generated by the previous cell that will hold the total number \n",
    "#              and mean quality scores of reads that do not meet the qual_score_cutoff\n",
    "# file_start: int that designates the index of the file to start analyzing, typically 0\n",
    "\n",
    "def count_barcodes(lib_bc_list, list_of_samps, fastq_paths, \n",
    "                   qual_score_cutoff, \n",
    "                   counts_df, rec_df, qual_acc_df, qual_dis_df,\n",
    "                   file_start): \n",
    "    \n",
    "    ## SET UP FILE AND INDEX TRACKERS \n",
    "    \n",
    "    # Define a current file index\n",
    "    current_file_index = file_start\n",
    "    \n",
    "    \n",
    "    ## CREATE A DICTIONARY TO STORE BARCODE COUNTS \n",
    "\n",
    "    # Set all keys to the barcodes in the library and all values to 0\n",
    "    # Note: barcodes are obtained from 'Barcode Sequence (Reverse)' because Read 2 is being analyzed.  \n",
    "    bc_dict = dict.fromkeys(bc_df['Barcode Sequence (Reverse)'], 0)\n",
    "    \n",
    "    \n",
    "    ## OBTAIN THE BARCODES FROM EACH FILE \n",
    "\n",
    "    # Loop through each of the files \n",
    "    for current_file in fastq_paths[file_start:]:\n",
    "        \n",
    "        # Check that files are loading \n",
    "        print(f'Checking File = {current_file_index}')\n",
    "\n",
    "        # Create a read counter \n",
    "        num_reads = 0 \n",
    "\n",
    "        # Create a barcode counter \n",
    "        num_bcs_recovered = 0\n",
    "            \n",
    "        # Create read counters for the quality score metrics\n",
    "        num_accepted_reads = 0\n",
    "        num_discarded_reads = 0\n",
    "            \n",
    "        # Create a list to store the mean read quality scores\n",
    "        # Note: these will be averaged later. \n",
    "        mean_qual_score_accepted_reads = []\n",
    "        mean_qual_score_discarded_reads = []\n",
    "            \n",
    "\n",
    "        ## PARSE THE READS\n",
    "    \n",
    "        # Create a sequence parser \n",
    "        seq_parser = SeqIO.parse(current_file, \"fastq\")\n",
    "        \n",
    "        # Iterate through the parser \n",
    "        while True: \n",
    "            \n",
    "            # Try to move to the next record \n",
    "            try: \n",
    "                \n",
    "                # Choose the next record\n",
    "                rec = next(seq_parser)\n",
    "                \n",
    "                # Add one to the read counter \n",
    "                num_reads += 1\n",
    "                \n",
    "                # Check if read is high-quality \n",
    "                if qual_score_cutoff > 0: \n",
    "                    \n",
    "                    # Obtain the Phred quality scores for the read \n",
    "                    qual_scores = rec.letter_annotations['phred_quality']\n",
    "\n",
    "                    # Calculate the mean quality score for the read \n",
    "                    mean_qual_score = np.mean(qual_scores)\n",
    "                    \n",
    "                    # If the mean quality score for the read is \n",
    "                    # less than the quality score cutoff, \n",
    "                    # move to the next read in the file; \n",
    "                    # otherwise, go through the rest of code in the for loop.\n",
    "                    if mean_qual_score >= qual_score_cutoff:\n",
    "                        mean_qual_score_accepted_reads.append(mean_qual_score)\n",
    "                        num_accepted_reads += 1 \n",
    "                    else: \n",
    "                        mean_qual_score_discarded_reads.append(mean_qual_score)       \n",
    "                        num_discarded_reads += 1   \n",
    "                        continue \n",
    "\n",
    "\n",
    "                # Obtain just the sequence from the read \n",
    "                current_seq = rec.seq\n",
    "\n",
    "                # Obtain the barcode from the barcode-containing region of the read \n",
    "                # Note: this is the location for Read 2.\n",
    "                read_bc = current_seq[46:54]\n",
    "\n",
    "                # Check if any barcode in the library matches the read sequence \n",
    "                if read_bc in bc_dict:\n",
    "                    \n",
    "                    # Update the dictionary entry for that barcode\n",
    "                    bc_dict[read_bc] = bc_dict.get(read_bc) + 1\n",
    "                    \n",
    "                    # Add one to the barcode counter \n",
    "                    num_bcs_recovered += 1\n",
    "                \n",
    "            # Stop the while loop once there is nothing \"next\" in the parser \n",
    "            # (i.e., once the last read in the file has been analyzed)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            # Print the error and move to the next record\n",
    "            except ValueError as e:\n",
    "                print(f'ValueError: {e}')\n",
    "                continue    \n",
    "                \n",
    "                \n",
    "        # Obtain the sample name to label columns in the dataframes\n",
    "        current_samp_name = list_of_samps[current_file_index]\n",
    "                \n",
    "        # Add the dictionary for the current sample to the barcode counts dataframe \n",
    "        counts_to_add_df = pd.DataFrame.from_dict(bc_dict, \n",
    "                                                  orient = 'index',\n",
    "                                                  columns = [current_samp_name])\n",
    "        \n",
    "        counts_df[current_samp_name] = counts_to_add_df[current_samp_name]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Add the read and barcode recovery info to the corresponding dataframes \n",
    "        rec_df.iloc[current_file_index, 0] = num_reads\n",
    "        rec_df.iloc[current_file_index, 1] = num_bcs_recovered\n",
    "        rec_df.iloc[current_file_index, 2] = round(num_bcs_recovered/num_reads*100,2)\n",
    "        \n",
    "        # Add the quality score info to the corresponding dataframes \n",
    "        qual_acc_df.iloc[current_file_index, 0] = num_accepted_reads\n",
    "        qual_acc_df.iloc[current_file_index, 1] = np.mean(mean_qual_score_accepted_reads)\n",
    "        \n",
    "        qual_dis_df.iloc[current_file_index, 0] = num_discarded_reads\n",
    "        qual_dis_df.iloc[current_file_index, 1] = np.mean(mean_qual_score_discarded_reads)\n",
    "        \n",
    "            \n",
    "        # Update the current file index \n",
    "        current_file_index += 1   \n",
    "                \n",
    "        \n",
    "        # Reset the counts in the dictionary for the next sample\n",
    "        bc_dict =  {x:0 for x in bc_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded99ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for storing barcode counts and barcode recovery information \n",
    "\n",
    "# Note: 'Sequencing_Run_Title' should be replaced with the column header of the sequencing run of interest\n",
    "#       from the Excel file with the sample lists. \n",
    "\n",
    "counts, rec, acc, dis = make_bc_dfs(list_of_samps = samp_df['Sequencing_Run_Title'], \n",
    "                                    lib_bc_list = list(bc_df['Barcode Sequence (Reverse)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363675e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the library member barcodes in the specified FASTQ files\n",
    "\n",
    "# Note: 'Sequencing_Run_Title' should be replaced with the column header of the sequencing run of interest\n",
    "#       from the Excel file with the sample lists (Samples List.xlsx > samp_df). \n",
    "\n",
    "# Note: corresponding FASTQ files and sample names must be indexed identically before being passed \n",
    "#       as arguments to the parameters \"fastq_paths\" and \"list_of_samps\", respectively. \n",
    "#       Ordering the files and sample names differently will lead to incorrect \n",
    "#       barcode count assignments for the samples. \n",
    "\n",
    "count_barcodes(lib_bc_list = list(bc_df['Barcode Sequence (Reverse)']), # Note: this checks for barcodes in Read 2. \n",
    "               list_of_samps = samp_df['Sequencing_Run_Title'],\n",
    "               fastq_paths = fastq_paths_r2, \n",
    "               qual_score_cutoff = 20, # Note: this indicates a Phred score cutoff of 20 (99% base call accuracy). \n",
    "               counts_df = counts, \n",
    "               rec_df = rec, \n",
    "               qual_acc_df = acc, \n",
    "               qual_dis_df = dis,\n",
    "               file_start = 0) # Note: this starts at the first file in the list. \n",
    "                               #       File subsets can be analyzed by changing this argument; \n",
    "                               #       in that case, list_of_samps must also be updated to select \n",
    "                               #       the correct set of sample names for the corresponding FASTQ files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a507048",
   "metadata": {},
   "source": [
    "# Add library member information to the barcode count dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ead0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the order of the barcodes remained the same \n",
    "print(np.unique(bc_df['Barcode Sequence (Reverse)'] == counts.index))\n",
    "\n",
    "# Note: the output should be \"True\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the indices in the barcode count dataframe with the library member names\n",
    "counts.index = list(bc_df['Library Member Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the list of library members \n",
    "print(list(bc_df['Library Member Name']))\n",
    "print(len(bc_df['Library Member Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb39f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ordered list of library members \n",
    "ordered_list_of_lib_mems = ['Wuhan Strain', 'D614G', \n",
    "                            'B.1.1.277', 'B.1.1.298', 'B.1.1.302', \n",
    "                            'B.1.1.7',\n",
    "                            'B.1.160',\n",
    "                            'B.1.221',\n",
    "                            'B.1.258', \n",
    "                            'B.1.351 v1', 'B.1.351 v2', 'B.1.351 v3', 'B.1.367',\n",
    "                            'B.1.429',\n",
    "                            'B.1.525', 'B.1.526', 'B.1.526.1', 'B.1.526.2',\n",
    "                            'B.1.617',\n",
    "                            'P.1', 'P.2',\n",
    "                            'SARS 2 N CTD only', 'SARS 2 E', 'SARS 2 M',\n",
    "                            'SARS-CoV-1', 'MERS',  \n",
    "                            'WIV1-CoV', 'MHV',\n",
    "                            'OC43', '229E', 'HKU1', 'NL63', \n",
    "                            'H1', 'H3', 'N1', 'N2',\n",
    "                            'RSV F',\n",
    "                            'Measles H', 'Measles F',\n",
    "                            'CMV gB', 'EBV gB',\n",
    "                            'HIV  SOSIP Pstalk', \n",
    "                            'Nipah Virus G', \n",
    "                            'Dengue Virus Type 2 Monomer', 'Dengue Virus Type 2 Dimer',\n",
    "                            '10% Ladder','1% Ladder','0.1% Ladder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febba4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the rows of the dataframes \n",
    "counts = counts.reindex(ordered_list_of_lib_mems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframes to files \n",
    "# Note: replace 'DATE SEQUENCING_RUN_NAME' with the date of file creation \n",
    "#       and a description of the sequencing run\n",
    "counts.to_csv('DATE SEQUENCING_RUN_NAME Barcode Counts.csv')\n",
    "rec.to_csv('DATE SEQUENCING_RUN_NAME Barcode Recovery.csv')\n",
    "acc.to_csv('DATE SEQUENCING_RUN_NAME Accepted Reads.csv')\n",
    "dis.to_csv('DATE SEQUENCING_RUN_NAME Discarded Reads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9edb0",
   "metadata": {},
   "source": [
    "# Combine data from multiple replicates/lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9a855",
   "metadata": {},
   "source": [
    "If processing multiple replicates/lanes of data for the same samples, make sure to sum corresponding barcode counts before proceeding. The following cells provide examples of how to combine barcode counts from different replicates/lanes and update the barcode recovery metrics. \n",
    "\n",
    "The example provides code for four lanes/replicates. When generating the dataframes above, name them clearly to indicate which dataframe corresponds to which lane/replicate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b99a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add barcode count dataframes together in an element-wise fashion \n",
    "total_counts = counts_1 + counts_2 + counts_3 + counts_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e85baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe to hold the total recovery stats\n",
    "total_rec = pd.DataFrame(index = rec_1.index, \n",
    "                         columns = rec_1.columns)\n",
    "\n",
    "total_rec['Number of Reads per Sample'] = rec_1['Number of Reads per Sample'] + \\\n",
    "                                          rec_2['Number of Reads per Sample'] + \\\n",
    "                                          rec_3['Number of Reads per Sample'] + \\\n",
    "                                          rec_4['Number of Reads per Sample']\n",
    "\n",
    "total_rec['Number of Barcodes Recovered per Sample'] = rec_1['Number of Barcodes Recovered per Sample'] + \\\n",
    "                                                       rec_2['Number of Barcodes Recovered per Sample'] + \\\n",
    "                                                       rec_3['Number of Barcodes Recovered per Sample'] + \\\n",
    "                                                       rec_4['Number of Barcodes Recovered per Sample']\n",
    "                \n",
    "total_rec['Percent Barcode Recovery'] = round(total_rec['Number of Barcodes Recovered per Sample']/total_rec['Number of Reads per Sample']*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b287fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe to hold the total accepted reads stats \n",
    "total_acc = pd.DataFrame(index = acc_1.index, \n",
    "                         columns = acc_1.columns)\n",
    "\n",
    "total_acc['Number of Accepted Reads'] = acc_1['Number of Accepted Reads'] + \\\n",
    "                                        acc_2['Number of Accepted Reads'] + \\\n",
    "                                        acc_3['Number of Accepted Reads'] + \\\n",
    "                                        acc_4['Number of Accepted Reads'] \n",
    "\n",
    "total_acc['Mean Quality Score'] = pd.concat([acc_1['Mean Quality Score'], acc_2['Mean Quality Score'],\n",
    "                                             acc_3['Mean Quality Score'], acc_4[['Mean Quality Score']]],\n",
    "                                            axis = 1).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe to hold the total discarded reads stats \n",
    "total_dis = pd.DataFrame(index = dis_1.index, \n",
    "                         columns = dis_1.columns)\n",
    "\n",
    "total_dis['Number of Discarded Reads'] = dis_1['Number of Discarded Reads'] + \\\n",
    "                                         dis_2['Number of Discarded Reads'] + \\\n",
    "                                         dis_3['Number of Discarded Reads'] + \\\n",
    "                                         dis_4['Number of Discarded Reads'] \n",
    "\n",
    "total_dis['Mean Quality Score'] = pd.concat([dis_1['Mean Quality Score'], dis_2['Mean Quality Score'],\n",
    "                                             dis_3['Mean Quality Score'], dis_4[['Mean Quality Score']]],\n",
    "                                            axis = 1).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all the total dataframes to csv files\n",
    "total_counts.to_csv('DATE SEQUENCING_RUN_NAME Total Barcode Counts.csv')\n",
    "total_rec.to_csv('DATE SEQUENCING_RUN_NAME Total Barcode Recovery.csv')\n",
    "total_acc.to_csv('DATE SEQUENCING_RUN_NAME Total Accepted Reads.csv')\n",
    "total_dis.to_csv('DATE SEQUENCING_RUN_NAME Total Discarded Reads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d52c58",
   "metadata": {},
   "source": [
    "# Visualize barcode recovery metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6caaa",
   "metadata": {},
   "source": [
    "#### Graph read counts, barcode counts, and barcode recovery across samples and library members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to report stats on the barcodes recovered\n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# rec_df: dataframe with barcode recovery information \n",
    "# num_bins: int with number of bins for the histogram\n",
    "\n",
    "def barcode_recovery(rec_df, num_bins): \n",
    "    \n",
    "    # Calculate average and median numbers of reads per sample\n",
    "    avg_reads = rec_df['Number of Reads per Sample'].mean()\n",
    "    med_reads = np.median(rec_df['Number of Reads per Sample'])\n",
    "    \n",
    "    # Plot reads per sample\n",
    "    sns.histplot(rec_df['Number of Reads per Sample'], bins = num_bins, color = 'lime')\n",
    "    plt.axvline(avg_reads, color = 'darkgreen', linestyle = 'dashed', linewidth = 1)\n",
    "    plt.axvline(med_reads, color = 'forestgreen', linestyle = 'dotted', linewidth = 1)\n",
    "    plt.xlabel('Number of Reads')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(f'Reads per Sample (Mean: {avg_reads:.2e} | Median: {med_reads:.2e})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate average and median numbers of barcodes recovered per sample\n",
    "    avg_bcs = rec_df['Number of Barcodes Recovered per Sample'].mean()\n",
    "    med_bcs = np.median(rec_df['Number of Barcodes Recovered per Sample'])\n",
    "    \n",
    "    # Plot barcodes recovered per sample\n",
    "    sns.histplot(rec_df['Number of Barcodes Recovered per Sample'], bins = num_bins, color = 'turquoise')\n",
    "    plt.axvline(avg_bcs, color = 'darkturquoise', linestyle = 'dashed', linewidth = 1)\n",
    "    plt.axvline(med_bcs, color = 'mediumturquoise', linestyle = 'dotted', linewidth = 1)\n",
    "    plt.xlabel('Number of Barcodes Recovered')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(f'Barcodes Recovered per Sample (Mean: {avg_bcs:.2e} | Median: {med_bcs:.2e})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate average and median percentages of reads with barcodes per sample\n",
    "    avg_rec = rec_df['Percent Barcode Recovery'].mean()\n",
    "    med_rec = np.median(rec_df['Percent Barcode Recovery'])\n",
    "    \n",
    "    # Plot percent barcode recovery per sample \n",
    "    sns.histplot(rec_df['Percent Barcode Recovery'], bins = num_bins, color = 'orchid')\n",
    "    plt.axvline(avg_rec, color = 'darkorchid', linestyle = 'dashed', linewidth = 1)\n",
    "    plt.axvline(med_rec, color = 'mediumorchid', linestyle = 'dotted', linewidth = 1)\n",
    "    plt.xlabel('Percent of Reads with Barcodes')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(f'Barcode Recovery Rates (Mean: {avg_rec:.1f}% | Median: {med_rec:.1f}%)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the recovery stats\n",
    "barcode_recovery(rec, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898283ab",
   "metadata": {},
   "source": [
    "#### Graph the barcode counts for each library member "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the number of barcodes counted for each library member \n",
    "bc_lib_mem_sums = pd.DataFrame(counts.sum(axis = 1), \n",
    "                               columns = ['Total Barcode Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdab1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the library member sums \n",
    "\n",
    "# Set figure size \n",
    "plt.figure(figsize = (70,15))\n",
    "\n",
    "# Create a range for the x-axis\n",
    "x_axis_lib_mem_sums = np.arange(len(bc_lib_mem_sums.index)) \n",
    "  \n",
    "# Create the bars in the plot \n",
    "plt.bar(x_axis_lib_mem_sums, bc_lib_mem_sums['Total Barcode Count'], \n",
    "        1, edgecolor = 'black') \n",
    "\n",
    "# Format the plot \n",
    "plt.xticks(x_axis_lib_mem_sums, bc_lib_mem_sums.index, \n",
    "           rotation = 30, ha = 'right', fontsize = 30) \n",
    "plt.yticks(fontsize = 30)\n",
    "plt.xlabel(\"Library Members\", fontsize = 50) \n",
    "plt.ylabel(\"Barcode Count\", fontsize = 50, labelpad = 20) \n",
    "plt.title(\"Barcode Count Recorded for Each Library Member\", fontsize = 60) \n",
    "plt.legend(fontsize = 40) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d61f973",
   "metadata": {},
   "source": [
    "#### Graph the read and barcode recovery data by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339954cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot different barcode recovery stats by sample\n",
    "\n",
    "# FUNCTION PARAMETERS \n",
    "# data_to_plot: list of 1D dataframes \n",
    "# bar_color: color for the bars\n",
    "# fig_w: int specifying the width of the figure\n",
    "# fig_h: int specifying the height of the figure\n",
    "# x_label: str with label for x-axis\n",
    "# y_label: str with label for y-axis\n",
    "# title: str with title for the plot\n",
    "# value_to_highlight: value in scientific notation at which to plot a horizontal line \n",
    "# y_min: minimum y-axis value \n",
    "# y_max: maximum y-axis value \n",
    "\n",
    "def plot_stats_by_sample(data_to_plot,\n",
    "                         bar_color,\n",
    "                         fig_w, fig_h,\n",
    "                         x_label, y_label, title,\n",
    "                         value_to_highlight = None,\n",
    "                         y_min = None, y_max = None): \n",
    "    \n",
    "    # Set figure size \n",
    "    plt.figure(figsize = (fig_w, fig_h))\n",
    "    \n",
    "    # Create a range for the x-axis \n",
    "    x_axis_samp_sums = np.arange(96) # Note: this assumes that the dataframes contain 96 samples each.  \n",
    "    \n",
    "    # Create the bars in the plot \n",
    "    plt.bar(x_axis_samp_sums, data_to_plot, \n",
    "            color = bar_color, edgecolor = 'black', linewidth = 2) \n",
    "  \n",
    "    # Format the plot \n",
    "    plt.xticks(x_axis_samp_sums, data_to_plot.index, \n",
    "               rotation = 30, ha = 'right', fontsize = 35) \n",
    "    plt.yticks(fontsize = 35)\n",
    "    plt.xlabel(x_label, fontsize = 45) \n",
    "    plt.ylabel(y_label, fontsize = 45) \n",
    "    plt.ylim(bottom = y_min, top = y_max)\n",
    "    plt.title(title, fontsize = 60) \n",
    "\n",
    "    # Add the horizontal line \n",
    "    if value_to_highlight != None: \n",
    "        plt.axhline(y = value_to_highlight, color = 'black', \n",
    "                    linestyle = 'dashed', linewidth = 5) \n",
    "\n",
    "    # Add horizontal grid lines \n",
    "    plt.grid(axis = 'y', color = 'grey')\n",
    "    ax = plt.gca()\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fca6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of reads per sample \n",
    "plot_stats_by_sample(data_to_plot = rec['Number of Reads per Sample'],\n",
    "                     bar_color = 'lime',\n",
    "                     fig_w = 150, fig_h = 15,\n",
    "                     x_label = 'Sample', \n",
    "                     y_label = 'Number of Reads', \n",
    "                     title = 'Number of Reads per Sample',\n",
    "                     y_max = 0.8e6) # Note: change this value for the data being analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of barcodes per sample\n",
    "plot_stats_by_sample(data_to_plot = rec['Number of Barcodes Recovered per Sample'],\n",
    "                     bar_color = 'turquoise',\n",
    "                     fig_w = 150, fig_h = 15,\n",
    "                     x_label = 'Sample', \n",
    "                     y_label = 'Number of Barcodes Recovered', \n",
    "                     title = 'Number of Barcodes Recovered per Sample',\n",
    "                     y_max = 0.5e6) # Note: change this value for the data being analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aab76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the barcode recovery rate for each sample\n",
    "plot_stats_by_sample(data_to_plot = rec['Percent Barcode Recovery'],\n",
    "                     bar_color = 'orchid',\n",
    "                     fig_w = 150, fig_h = 15,\n",
    "                     x_label = 'Sample', \n",
    "                     y_label = '% Reads with Barcodes Recovered', \n",
    "                     title = 'Barcode Recovery per Sample',\n",
    "                     y_max = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055fe7b",
   "metadata": {},
   "source": [
    "#### Graph the numbers of accepted vs discarded reads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8168274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to graph accepted and discarded read counts \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# acc_df: dataframe with counts of accepted reads \n",
    "# dis_df: dataframe with counts of discarded reads\n",
    "# fig_w: int specifying the width of the figure\n",
    "# fig_h: int specifying the height of the figure\n",
    "# title: str with title for the plot \n",
    "# y_max: maximum y-axis value \n",
    "# y_min: minimum y-axis value \n",
    "\n",
    "\n",
    "def plot_acc_dis_reads(acc_df, dis_df, \n",
    "                       fig_w, fig_h, \n",
    "                       title,\n",
    "                       y_max = None, y_min = None): \n",
    "\n",
    "    # Create a range for the x-axis\n",
    "    x_axis = np.arange(96) # Note: this assumes that the dataframes contain 96 samples each.  \n",
    "\n",
    "    # Set the figure size \n",
    "    plt.figure(figsize = (fig_w,fig_h))\n",
    "\n",
    "    # Create the bars in the plot \n",
    "    plt.bar(x_axis, acc_df['Number of Accepted Reads'], \n",
    "            label = 'Accepted', color = 'gray') \n",
    "    plt.bar(x_axis, dis_df['Number of Discarded Reads'], \n",
    "            label = 'Discarded', color = 'orange',\n",
    "            bottom = acc_df['Number of Accepted Reads']) \n",
    "\n",
    "    # Format the plot \n",
    "    plt.xticks(x_axis, acc_df.index, \n",
    "               rotation = 30, ha = 'right', fontsize = 35) \n",
    "    plt.yticks(fontsize = 35)\n",
    "    plt.xlabel(\"Samples\", fontsize = 45, labelpad = 30) \n",
    "    plt.ylabel(\"Number of Reads\", fontsize = 45, labelpad = 30) \n",
    "    plt.title(title, fontsize = 60, pad = 30) \n",
    "    plt.ylim(bottom = y_min, top = y_max)\n",
    "    plt.legend(fontsize = 50, loc = 'upper right') \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the numbers of accepted and discarded reads \n",
    "plot_acc_dis_reads(acc_df = acc, \n",
    "                   dis_df = dis, \n",
    "                   fig_w = 150, fig_h = 15, \n",
    "                   title = 'Accepted and Discarded Reads',\n",
    "                   y_max = 0.8e6) # Note: change this value for the data being analyzed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe7b42",
   "metadata": {},
   "source": [
    "#### Graph the quality scores for the accepted and discarded reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to graph the quality score data \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# acc_df: dataframe with counts of accepted reads \n",
    "# dis_df: dataframe with counts of discarded reads\n",
    "# fig_w: int specifying the width of the figure\n",
    "# fig_h: int specifying the height of the figure\n",
    "# title: str with title for the plot \n",
    "# y_max: maximum y-axis value \n",
    "# y_min: minimum y-axis value \n",
    "\n",
    "def plot_q_scores(acc_df, dis_df, \n",
    "                  fig_w, fig_h, \n",
    "                  title, y_max = None, y_min = None):\n",
    "\n",
    "    # Create a range for the x-axis\n",
    "    x_axis = np.arange(96) # Note: this assumes that the dataframes contain 96 samples each.  \n",
    "\n",
    "    # Set the figure size \n",
    "    plt.figure(figsize = (fig_w,fig_h))\n",
    "\n",
    "    # Create the bars in the plot \n",
    "    plt.bar(x_axis + 0, acc_df['Mean Quality Score'], \n",
    "            0.2, label = 'Accepted', color = 'gray') \n",
    "    plt.bar(x_axis + 0.2, dis_df['Mean Quality Score'], \n",
    "            0.2, label = 'Discarded', color = 'orange')\n",
    "\n",
    "    # Format the plot \n",
    "    plt.xticks(x_axis, acc_df.index, \n",
    "               rotation = 30, ha = 'right', fontsize = 30) \n",
    "    plt.yticks(fontsize = 30)\n",
    "    plt.xlabel(\"Samples\", fontsize = 45, labelpad = 30) \n",
    "    plt.ylabel(\"Mean Quality Score\", fontsize = 45, labelpad = 30) \n",
    "    plt.title(title, fontsize = 60, pad = 30)\n",
    "    plt.ylim(bottom = y_min, top = y_max)\n",
    "    plt.legend(fontsize = 30, loc = 'upper right') \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0faf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the quality score info\n",
    "plot_q_scores(acc_df = acc, \n",
    "              dis_df = dis, \n",
    "              fig_w = 150, \n",
    "              fig_h = 15, \n",
    "              title = 'Mean Quality Scores for Accepted and Discarded Reads',\n",
    "              y_max = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578afb1",
   "metadata": {},
   "source": [
    "# Determine which ladder virus to use for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to graph ladder virus barcode counts\n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# bc_counts_df: dataframe with the barcode counts \n",
    "\n",
    "def plot_ladders(bc_counts_df): \n",
    "    \n",
    "    # Set the figure size \n",
    "    plt.figure(figsize = (150,15))\n",
    "\n",
    "    # Create a range for the x-axis\n",
    "    x_axis_ladder = np.arange(96) # Note: this assumes that the dataframes contain 96 samples each.  \n",
    "\n",
    "    # Create the bars in the plot \n",
    "    plt.bar(x_axis_ladder - 0.3, bc_counts_df.loc['10% Ladder'], \n",
    "            0.2, label = '10% Ladder', color = '#C5E898', edgecolor = 'black') \n",
    "    plt.bar(x_axis_ladder - 0.1, bc_counts_df.loc['1% Ladder'], \n",
    "            0.2, label = '1% Ladder', color = '#29ADB2', edgecolor = 'black') \n",
    "    plt.bar(x_axis_ladder + 0.1, bc_counts_df.loc['0.1% Ladder'], \n",
    "            0.2, label = '0.1% Ladder', color = '#0766AD', edgecolor = 'black') \n",
    "\n",
    "    # Format the plot \n",
    "    plt.xticks(x_axis_ladder, bc_counts_df.columns, rotation = 30, \n",
    "               ha = 'right', fontsize = 30) \n",
    "    plt.yticks(fontsize = 30)\n",
    "    plt.xlabel(\"Samples\", fontsize = 40, labelpad = 30) \n",
    "    plt.ylabel(\"Ladder Virus Barcode Count\", fontsize = 40, labelpad = 30) \n",
    "    plt.legend(fontsize = 40, loc = 'upper right') \n",
    "\n",
    "    # Calculate the mean of all the barcode counts (excluding the ladder viruses' barcode counts)\n",
    "    mean_bc_count = bc_counts_df.iloc[:-3,:].mean().mean()\n",
    "\n",
    "    # Add the horizontal line \n",
    "    plt.axhline(y = mean_bc_count, color = 'black', linestyle = 'dashed', linewidth = 5) \n",
    "\n",
    "    plt.title(f\"Ladder Virus Barcode Counts for Each Sample - Mean Non-Ladder Library Member Barcode Count: {mean_bc_count:.0f}\", \n",
    "              fontsize = 50, pad = 40) \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot of the ladder virus barcode counts\n",
    "plot_ladders(counts)\n",
    "\n",
    "# Use the 1% ladder for ARCADE samples \n",
    "# Use the 10% ladder for the neutralization assay samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87177d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine how many samples \n",
    "# have ladder virus barcode counts below a certain threshold \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# bc_counts_df: dataframe containing the ladder virus barcode counts \n",
    "# thresholds: list with minimum barcode count (int) acceptable for each ladder \n",
    "# plate_run_desc: description of the plate/run \n",
    "\n",
    "def ladder_threshold(bc_counts_df, thresholds, plate_run_desc): \n",
    "    \n",
    "    # Create a list of the ladder virus labels matching the labels in the dataframe\n",
    "    ladders = ['10% Ladder', '1% Ladder', '0.1% Ladder']\n",
    "    \n",
    "    # Loop through all the ladder viruses\n",
    "    for lad in range(len(ladders)): \n",
    "        \n",
    "        # Print a header for the current ladder virus being checked\n",
    "        print(f'{plate_run_desc} samples with low {ladders[lad]} barcode counts')\n",
    "        \n",
    "        # Loop through all the samples \n",
    "        for samp in range(len(bc_counts_df.columns)): \n",
    "\n",
    "            # Obtain the ladder virus barcode count for the current sample \n",
    "            samp_lad_count = bc_counts_df.loc[ladders[lad]][samp]\n",
    "\n",
    "            # Check if the ladder virus barcode count for the sample is below the acceptable threshold\n",
    "            if samp_lad_count < thresholds[lad]: \n",
    "\n",
    "                # Print the names of samples with low ladder virus barcode counts \n",
    "                print(f'Sample: {bc_counts_df.columns[samp]} | Barcode Count: {samp_lad_count}')\n",
    "                \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report samples with low ladder virus barcode counts to determine which ladder virus to use for normalization \n",
    "ladder_threshold(bc_counts_df = counts, \n",
    "                 thresholds = [500, 50, 5],\n",
    "                 plate_run_desc = \"Example Run\")\n",
    "\n",
    "# 10% Ladder\n",
    "# - Usually only samples that did not receive the ladder viruses have low barcode counts for this ladder virus\n",
    "# - Barcode counts for this ladder virus tend to be very elevated compared to the library member barcode counts\n",
    "\n",
    "# 1% Ladder\n",
    "# - Some neutralization assay samples have low barcode counts even for this ladder virus \n",
    "\n",
    "# 0.1% Ladder \n",
    "# - Most ARCADE and neutralization assay samples have low barcode counts for this ladder virus \n",
    "\n",
    "# Use the 10% Ladder for the neutralization assay samples\n",
    "# Use the 1% Ladder for the ARCADE samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f57df",
   "metadata": {},
   "source": [
    "# Normalize the library member barcode counts for each sample using the selected ladder virus's barcode counts for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to normalize barcode counts using a ladder virus's barcode counts\n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# bc_counts_df: dataframe containing the barcode counts for all samples and library members and ladder viruses\n",
    "# ladder_to_use: str with the name of the ladder to use \n",
    "# plate_run_desc: str with a description of the plate/run \n",
    "# date: str with the date of data normalization \n",
    "\n",
    "def normalize_bc_counts(bc_counts_df, ladder_to_use, plate_run_desc, date): \n",
    "    \n",
    "    # Create an empty dataframe to store the normalized counts\n",
    "    counts_norm = pd.DataFrame(index = bc_counts_df.index, \n",
    "                               columns = bc_counts_df.columns)\n",
    "\n",
    "    # Loop through the samples in the dataframe \n",
    "    for samp in range(len(bc_counts_df.columns)): \n",
    "\n",
    "        # Obtain the ladder virus barcode count from the current sample\n",
    "        ladder_divisor = bc_counts_df.loc[ladder_to_use][samp]\n",
    "\n",
    "        # Make sure the current ladder virus barcode count is not 0\n",
    "        if ladder_divisor > 0: \n",
    "\n",
    "            # Loop through the library members in the dataframe \n",
    "            for mem in range(len(bc_counts_df.index)):\n",
    "\n",
    "                # Record the rounded normalized barcode counts\n",
    "                counts_norm.iloc[mem, samp] = round(bc_counts_df.iloc[mem, samp]/ladder_divisor, 2)\n",
    "\n",
    "            # Note: any samples with a ladder virus barcode count of 0 will have NaN in the corresponding \n",
    "            #       locations in the dataframe\n",
    "        \n",
    "        # Report samples with ladder virus barcode counts of 0 \n",
    "        else: \n",
    "            print('Sample', bc_counts_df.columns[samp], 'has a', \n",
    "                  ladder_to_use, 'barcode count of', ladder_divisor)\n",
    "            \n",
    "    # Write normalized counts to a CSV file \n",
    "    counts_norm.to_csv(f'{date} {plate_run_desc} - Ladder-Normalized Barcode Counts.csv')\n",
    "    \n",
    "    return counts_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize library member barcode counts by the ladder virus barcode counts \n",
    "norm_counts = normalize_bc_counts(bc_counts_df = counts, \n",
    "                                  ladder_to_use = \"1% Ladder\", # Note: change this selection based on the above analysis. \n",
    "                                  plate_run_desc = \"Example ARCADE Assay\", # Note: change this for the data being analyzed. \n",
    "                                  date = \"20251231\") # Note: change this based on the date normalization is performed.\n",
    "\n",
    "# Note: samples that were not provided ladder virus should report ladder virus barcode counts of 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a664ba",
   "metadata": {},
   "source": [
    "At this point, samples corresponding to flow cytometry controls (e.g., NT = Not Transduced) and library members corresponding to the ladder viruses can be removed from the dataframe. The following cell provides example code that can perform these removal steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44371a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the flow cytometry controls (e.g., NT) and ladders from the ladder-normalized barcode counts dataframe \n",
    "\n",
    "# Obtain the samples to remove corresponding to the flow cytometry controls \n",
    "samples_to_remove = []\n",
    "\n",
    "# Loop through the columns in the dataframe to find the samples to remove \n",
    "for col in range(len(norm_counts.columns)): \n",
    "\n",
    "    if \"NT\" in norm_counts.columns[col]: \n",
    "\n",
    "        samples_to_remove.append(norm_counts.columns[col])\n",
    "\n",
    "    elif \"CD-594-Ctrl\" in norm_counts.columns[col]: \n",
    "\n",
    "        samples_to_remove.append(norm_counts.columns[col])\n",
    "\n",
    "# Print the samples being removed \n",
    "print(samples_to_remove)\n",
    "\n",
    "# Remove the columns with the flow cytometry controls\n",
    "norm_counts.drop(labels = samples_to_remove, # Note: change this based on the samples in the sample list. \n",
    "                 axis = 1, \n",
    "                 inplace = True)\n",
    "\n",
    "# Remove the rows with the ladder virus values \n",
    "norm_counts.drop(labels = ['10% Ladder', '1% Ladder', '0.1% Ladder'],\n",
    "                 axis = 0, \n",
    "                 inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67facd",
   "metadata": {},
   "source": [
    "# Calculate averages and standard deviations across replicates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b42413",
   "metadata": {},
   "source": [
    "In the ARCADE paper, ladder-normalized barcode counts are referred to as \"ladder-normalized barcode fractions.\" The variable \"norm_counts\" in the following cells contains these \"ladder-normalized barcode fractions.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the names of the samples in the ladder-normalized barcode counts dataframe \n",
    "\n",
    "# Create a list for storing the names \n",
    "samp_list = []\n",
    "\n",
    "# Loop through each sample\n",
    "for samp in norm_counts.columns: \n",
    "    \n",
    "    # Remove the replicate number from the sample \n",
    "    samp_name = samp_name[:-2]\n",
    "    \n",
    "    # Add the sample name to the list if it hasn't been added yet\n",
    "    if samp_name not in samp_list: \n",
    "        samp_list.append(samp_name)\n",
    "\n",
    "# Observe the list \n",
    "print(samp_list)\n",
    "print(len(samp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for storing the averages of the replicates\n",
    "norm_avgs = pd.DataFrame(0, \n",
    "                         index = norm_counts.index, \n",
    "                         columns = samp_list)\n",
    "\n",
    "# Create a dataframe for storing the standard deviations of the replicates \n",
    "norm_stds = pd.DataFrame(0, \n",
    "                         index = norm_counts.index, \n",
    "                         columns = samp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute averages and standard deviations and store them in the appropriate location in the dataframe \n",
    "\n",
    "# Loop through the rows in the dataframe with the sample library member barcode counts\n",
    "for row in range(norm_counts.shape[0]): \n",
    "\n",
    "    # Loop through the sample names \n",
    "    for col in range(len(samp_list)):\n",
    "        \n",
    "        # Obtain the values to average (every three columns)\n",
    "        start_val = col*3\n",
    "        end_val = col*3 + 3\n",
    "        vals_to_use = norm_counts.iloc[row, start_val:end_val]\n",
    "        \n",
    "        # Add average value\n",
    "        norm_avgs.iloc[row, col] = round(vals_to_use.mean(), 2)\n",
    "        \n",
    "        # Add standard deviation value \n",
    "        norm_stds.iloc[row, col] = round(vals_to_use.std(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes to files \n",
    "norm_avgs.to_csv('DATE SEQUENCING_RUN_NAME 1% Ladder-Normalized Barcode Fractions - Averages.csv')\n",
    "norm_stds.to_csv('DATE SEQUENCING_RUN_NAME 1% Ladder-Normalized Barcode Fractions - Standard Deviations.csv')\n",
    "\n",
    "# Note: change 'DATE SEQUENCING_RUN_NAME' based on the experiment being analyzed. \n",
    "# Note: change the ladder virus listed if not using the 1% ladder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b895184",
   "metadata": {},
   "source": [
    "# Perform double normalization using the No Serum/Virus Only samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8aa6f8",
   "metadata": {},
   "source": [
    "Note: for the neutralization assay, samples labeled VO (Virus Only) were used for normalization. These samples are conceptually the same as the ARCADE No Serum samples, but they utilize the lentiviral library doses, cell line, and incubation time for the neutralization assay.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2596328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the No Serum samples' sample names\n",
    "\n",
    "# Note: ensure these names match those in the norm_avgs and norm_stds dataframes\n",
    "ns_samp_names = ['No Serum 1', 'No Serum 2', 'No Serum 3',\n",
    "                 'No Serum 4', 'No Serum 5', 'No Serum 6', \n",
    "                 'No Serum 7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80312e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for storing the pooled standard deviations of the No Serum samples' \n",
    "# ladder-normalized barcode fractions for each library member\n",
    "no_serum_avg_std = pd.DataFrame(index = norm_avgs.index,\n",
    "                                columns = ['No Serum Pooled Avg', 'No Serum Pooled SD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average all No Serum samples' average ladder-normalized barcode fractions\n",
    "\n",
    "# Note: this is averaging across sample columns. \n",
    "no_serum_avg_std['No Serum Pooled Avg'] = norm_avgs.loc[:,ns_samp_names].mean(axis = 1).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the pooled standard deviations for the No Serum samples \n",
    "\n",
    "# Note: this is only necessary if using No Serum sample replicates across plates for normalization. \n",
    "#       The ARCADE data on the SRA contains No Serum samples from 7 separate plates \n",
    "#       with 3 replicates per plate. The neutralization assay data on the SRA, however, \n",
    "#       contains No Serum/Virus Only samples for three different lentiviral library doses \n",
    "#       with three replicates per sample from a single plate. A simple standard deviation \n",
    "#       can be used instead of a pooled standard deviation if the replicates being averaged \n",
    "#       are not grouped in any way (i.e., not belonging to different plates). \n",
    "\n",
    "# Loop through each library member \n",
    "for mem in no_serum_avg_std.index: \n",
    "    \n",
    "    # Calculate the pooled standard deviation \n",
    "    \n",
    "    # Set the squared standard deviation sum to zero \n",
    "    sd_sq_sum = 0\n",
    "    \n",
    "    # Set the number of elements to zero (it should always end up as 7)\n",
    "    k = 0\n",
    "\n",
    "    # Loop through each No Serum sample \n",
    "    for samp in ns_samp_names: \n",
    "\n",
    "        # Calculate the square of the standard deviation \n",
    "        sd_sq_sum = sd_sq_sum + norm_stds.loc[mem,samp]**2\n",
    "        k = k + 1\n",
    "    \n",
    "    no_serum_avg_std.loc[mem, 'No Serum Pooled SD'] = math.sqrt(sd_sq_sum / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42287bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the No Serum samples' average ladder-normalized barcode fractions with standard deviations as error bars \n",
    "\n",
    "# Create a figure \n",
    "plt.figure(figsize = (50, 10))\n",
    "plt.grid(axis = 'y', color = 'grey')\n",
    "\n",
    "# Create a list of colors to categorize the library members \n",
    "color_list = ['#8CFF00']*21 + ['#E6BD00']*3 + ['#E52EB5']*8 + ['#00ADC3']*4 + ['#BDBCBC']*9\n",
    "\n",
    "# Produce the plot \n",
    "plt.bar(no_serum_avg_std.index,\n",
    "        no_serum_avg_std['No Serum Pooled Avg'],\n",
    "        yerr = no_serum_avg_std['No Serum Pooled SD'],\n",
    "        edgecolor = 'black',\n",
    "        color = color_list, \n",
    "        linewidth = 4, \n",
    "        error_kw = dict(lw = 5))\n",
    "\n",
    "# Create a legend \n",
    "no_serum_legend = [mpatches.Patch(facecolor = '#8CFF00',\n",
    "                                  label = 'SARS-CoV-2 Spike Variants',\n",
    "                                  edgecolor = 'black',\n",
    "                                  linewidth = 2),\n",
    "                   mpatches.Patch(facecolor = '#E6BD00',\n",
    "                                  label = 'SARS-CoV-2 Non-Spike Proteins',\n",
    "                                  edgecolor = 'black',\n",
    "                                  linewidth = 2),\n",
    "                   mpatches.Patch(facecolor = '#E52EB5',\n",
    "                                  label = 'Additional Coronavirus Proteins',\n",
    "                                  edgecolor = 'black',\n",
    "                                  linewidth = 2),\n",
    "                   mpatches.Patch(facecolor = '#00ADC3',\n",
    "                                  label = 'Influenza Envelope Proteins',\n",
    "                                  edgecolor = 'black',\n",
    "                                  linewidth = 2),\n",
    "                   mpatches.Patch(facecolor = '#BDBCBC',\n",
    "                                  label = 'Other Viral Proteins',\n",
    "                                  edgecolor = 'black',\n",
    "                                  linewidth = 2)]\n",
    "\n",
    "# Format the plot\n",
    "plt.xticks(rotation = 30, ha = 'right', fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "plt.xlabel('Library Members', fontsize = 35)\n",
    "plt.ylabel('Ladder-Normalized \\nBarcode Fraction', fontsize = 35, labelpad = 20)\n",
    "plot_title = 'Pooled Average Ladder-Normalized Barcode Fractions for the No Serum Samples\\n'\n",
    "plt.title(plot_title, fontsize = 50, pad = 20)\n",
    "\n",
    "plt.legend(handles = no_serum_legend, bbox_to_anchor = (0.995, 1.15),\n",
    "           fontsize = 30, frameon = True, ncol = 5, edgecolor = 'grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each sample's average library member ladder-normalized barcode fractions \n",
    "# by the corresponding No Serum samples' average library member ladder-normalized barcode fractions\n",
    "avgs_no_serum_norm = norm_avgs.div(no_serum_avg_std['No Serum Pooled Avg'], axis = 'index').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform error propagation to calculate the standard deviations of the double-normalized barcode fractions\n",
    "\n",
    "# Define a function to perform the error propagation \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# avgs_df: dataframe with average ladder-normalized barcode fractions for all samples\n",
    "# stds_df: dataframe with standard deviations of ladder-normalized barcode fractions for all samples\n",
    "# no_serum_df: dataframe with average and standard deviations of ladder-normalized barcode fractions \n",
    "#              for only the No Serum samples\n",
    "# no_serum_norm_avg_df: dataframe with average sample ladder-normalized barcode fractions divided \n",
    "#                       by average No Serum ladder-normalized barcode fractions \n",
    "\n",
    "# Note: avgs_df, stds_df, and no_serum_norm_avg_df must have the same dimensions and orientation\n",
    "# Note: no_serum_df must have the same number and order of rows as the others\n",
    "\n",
    "def calc_no_serum_error_prop(avgs_df, stds_df, \n",
    "                             no_serum_df, no_serum_norm_avg_df): \n",
    "\n",
    "    # Create a new dataframe to return \n",
    "    no_serum_stds = pd.DataFrame(index = stds_df.index, \n",
    "                                 columns = stds_df.columns)\n",
    "    \n",
    "    # Calculate the new standard deviations \n",
    "    # Note: if x = a/b, then SD_x/x = sqrt((SD_a/a)^2 + (SD_b/b)^2)\n",
    "    # Loop through each sample \n",
    "    for i in range(len(stds_df.columns)): \n",
    "        \n",
    "        # Loop through each library member \n",
    "        for j in range(len(stds_df.index)): \n",
    "                   \n",
    "            # Obtain the sample SD and mean for that library member\n",
    "            SD_a = stds_df.iloc[j,i]\n",
    "            a = avgs_df.iloc[j,i]\n",
    "            \n",
    "            # Obtain the No Serum SD and mean for that library member\n",
    "            SD_b = no_serum_df['No Serum Pooled SD'][j]\n",
    "            b = no_serum_df['No Serum Pooled Avg'][j]\n",
    "                   \n",
    "            # Obtain the new average (the ratio of the sample average to the No Serum average)\n",
    "            x = no_serum_norm_avg_df.iloc[j,i]\n",
    "            \n",
    "            # Check that values are being assigned  \n",
    "            # print('SD_a: ' + str(SD_a) + ' | a: ' + str(a) + \n",
    "            #       ' |SD_b: ' + str(SD_b) + ' | b: ' + str(b) +  \n",
    "            #       ' | x: ' + str(x))\n",
    "                   \n",
    "            # Print if any values are zero \n",
    "            # if a == 0: \n",
    "            #     print('a is zero for ' + stds_df.columns[i] + ' ' + stds_df.index[j])\n",
    "            # if b == 0: \n",
    "            #     print('b is zero for ' + no_serum_df.index[j])\n",
    "                \n",
    "            # Calculate the new standard deviation \n",
    "            SD_x = round(x * math.sqrt((SD_a/a)**2 + (SD_b/b)**2),2)\n",
    "            \n",
    "            # Check that calculations are working \n",
    "            # print('SD_x: ' + str(SD_x))\n",
    "                   \n",
    "            # Add the new standard deviation to the new dataframe \n",
    "            no_serum_stds.iloc[j,i] = SD_x\n",
    "        \n",
    "    return no_serum_stds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviations for the double-normalized barcode fractions\n",
    "stds_no_serum_norm = calc_no_serum_error_prop(norm_avgs, norm_stds, \n",
    "                                              no_serum_avg_std, \n",
    "                                              avgs_no_serum_norm)\n",
    "\n",
    "# Note: certain library members' ladder-normalized barcode fractions may be 0 for the No Serum samples; \n",
    "#       this will prevent double normalization. The library members can be omitted from additional analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which samples cannot be double-normalized \n",
    "print(norm_avgs[norm_avgs.eq(0).any(axis = 1)])\n",
    "print(norm_stds[norm_stds.eq(0).any(axis = 1)])\n",
    "\n",
    "# Note: these commands will also show which library members \n",
    "#       have ladder-normalized barcode fractions of 0 for the No Serum samples. \n",
    "#       The non-spike SARS-CoV-2 library members often have ladder-normalized \n",
    "#       barcode fractions of 0 for the No Serum samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the double-normalized average and standard deviation dataframes\n",
    "avgs_no_serum_norm.to_csv('DATE SEQUENCING_RUN_NAME Double-Normalized Barcode Fractions - Averages.csv')\n",
    "stds_no_serum_norm.to_csv('DATE SEQUENCING_RUN_NAME Double-Normalized Barcode Fractions - Standard Deviations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba81f1",
   "metadata": {},
   "source": [
    "# Compute the Log2FC for the ladder-normalized and double-normalized barcode fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the Log2FC values from normalized values for every sample \n",
    "\n",
    "# FUNCTION PARAMETERS\n",
    "# avgs_df: dataframe with averages of normalized barcode fractions \n",
    "# stds_df: dataframe with standard deviations of normalized barcode fractions\n",
    "\n",
    "# Note: these two dataframes must match in their dimensions, indices, and columns. \n",
    "\n",
    "def calc_log2fc(avgs_df, stds_df): \n",
    "    \n",
    "    # Convert the averages \n",
    "    new_avgs_df = round(np.log2(avgs_df),2)\n",
    "    \n",
    "    # Create an empty dataframe to store the new standard deviations \n",
    "    new_stds_df = pd.DataFrame(index = stds_df.index,\n",
    "                               columns = stds_df.columns)\n",
    "    \n",
    "    # Loop through the dataframe and use log error propagation to calculate new standard deviations \n",
    "    # If x = log_2(a) --> SD_x = SD_a / (a * ln(2))\n",
    "    for n in range(len(stds_df.index)): \n",
    "        for m in range(len(stds_df.columns)): \n",
    "            \n",
    "            # Determine if there will be a divide-by-zero error \n",
    "            if avgs_df.iloc[n,m] == 0: \n",
    "                print('The average for ' + str(avgs_df.columns[m]) + ' ' + str(avgs_df.index[n]) + \n",
    "                      ' is 0.')\n",
    "            \n",
    "            # Calculate the SD \n",
    "            new_stds_df.iloc[n,m] = round(stds_df.iloc[n,m] / (avgs_df.iloc[n,m] * np.log(2)),2)\n",
    "            \n",
    "    return new_avgs_df, new_stds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24069715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log2-transform the averages and standard deviations of the normalized barcode fractions \n",
    "# using log error propagation\n",
    "\n",
    "# For the ladder-normalized barcode fractions \n",
    "log2_norm_avgs, log2_norm_stds = calc_log2fc(norm_avgs, norm_stds)\n",
    "\n",
    "# For the double-normalized barcode fractions \n",
    "log2_no_serum_norm_avgs, log2_no_serum_norm_stds = calc_log2fc(avgs_no_serum_norm, stds_no_serum_norm)\n",
    "\n",
    "# Note: The non-spike SARS-CoV-2 library members often cannot be log2-transformed\n",
    "#       as they often have normalized barcode fractions of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log2-transformed average and standard deviation dataframes\n",
    "log2_norm_avgs.to_csv('DATE SEQUENCING_RUN_NAME Log2 Double-Normalized Barcode Fractions - Avg.csv')\n",
    "log2_norm_stds.to_csv('DATE SEQUENCING_RUN_NAME Log2 Double-Normalized Barcode Fractions - SD.csv')\n",
    "\n",
    "log2_no_serum_norm_avgs.to_csv('DATE SEQUENCING_RUN_NAME Log2 Double-Normalized Barcode Fractions - Avg.csv')\n",
    "log2_no_serum_norm_stds.to_csv('DATE SEQUENCING_RUN_NAME Log2 Double-Normalized Barcode Fractions - SD.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
